# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MA6mvBV9YOgMyhCmJrNDRrqBpYqrW-he
"""

# Flask API para Neural Style Transfer sobre objetos detectados con YOLOv8 (Colab con pyngrok)



from flask import Flask, request, send_file
from flask_cors import CORS
from pyngrok import ngrok
from PIL import Image
import io
import os
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from torchvision import models
import torch.nn as nn
import torch.optim as optim
from ultralytics import YOLO
import copy

app = Flask(__name__)
CORS(app)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Configurar modelo y estilo
graffiti_dir = "/content/drive/MyDrive/DATASET_PDI/GRAFFITIS2"

def image_loader_from_array(img_array):
    transform = transforms.Compose([
        transforms.Resize((500, 500)),
        transforms.ToTensor()
    ])
    image = Image.fromarray(img_array).convert('RGB')
    image = transform(image).unsqueeze(0)
    return image.to(device, torch.float)

def load_all_style_images(folder_path, max_images=None):
    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(('jpg','jpeg','png'))]
    if max_images: files = files[:max_images]
    return [image_loader_from_array(cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB)) for f in files]

style_imgs = load_all_style_images(graffiti_dir, max_images=10)

cnn = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features.to(device).eval()
cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)
cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)

class Normalization(nn.Module):
    def __init__(self, mean, std):
        super().__init__()
        self.mean = mean.view(-1, 1, 1)
        self.std = std.view(-1, 1, 1)
    def forward(self, img):
        return (img - self.mean) / self.std

def gram_matrix(input):
    a, b, c, d = input.size()
    features = input.view(a * b, c * d)
    G = torch.mm(features, features.t())
    return G.div(a * b * c * d)

class ContentLoss(nn.Module):
    def __init__(self, target):
        super().__init__()
        self.target = target.detach()
    def forward(self, input):
        self.loss = nn.functional.mse_loss(input, self.target)
        return input

class MultiStyleLoss(nn.Module):
    def __init__(self, target_features_list):
        super().__init__()
        self.targets = [gram_matrix(f).detach() for f in target_features_list]
    def forward(self, input):
        G = gram_matrix(input)
        self.loss = sum(nn.functional.mse_loss(G, t) for t in self.targets) / len(self.targets)
        return input

def get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_imgs, content_img):
    cnn = copy.deepcopy(cnn)
    normalization = Normalization(normalization_mean, normalization_std).to(device)
    content_losses, style_losses = [], []
    model = nn.Sequential(normalization)
    i = 0
    for layer in cnn.children():
        if isinstance(layer, nn.Conv2d): i += 1; name = f'conv_{i}'
        elif isinstance(layer, nn.ReLU): name = f'relu_{i}'; layer = nn.ReLU(inplace=False)
        elif isinstance(layer, nn.MaxPool2d): name = f'pool_{i}'
        else: continue
        model.add_module(name, layer)
        if name == 'conv_4':
            target = model(content_img).detach()
            content_loss = ContentLoss(target)
            model.add_module("content_loss", content_loss)
            content_losses.append(content_loss)
        if name in ['conv_1','conv_2','conv_3','conv_4','conv_5']:
            targets = [model(s_img).detach() for s_img in style_imgs]
            style_loss = MultiStyleLoss(targets)
            model.add_module(f"style_loss_{i}", style_loss)
            style_losses.append(style_loss)
    return model, style_losses, content_losses

def run_style_transfer(model, input_img, style_losses, content_losses, num_steps=300):
    optimizer = optim.LBFGS([input_img.requires_grad_()])
    run = [0]
    while run[0] <= num_steps:
        def closure():
            input_img.data.clamp_(0, 1)
            optimizer.zero_grad()
            model(input_img)
            style_score = sum(sl.loss for sl in style_losses)
            content_score = sum(cl.loss for cl in content_losses)
            loss = style_score * 1e6 + content_score
            loss.backward()
            run[0] += 1
            return loss
        optimizer.step(closure)
    input_img.data.clamp_(0, 1)
    return input_img

@app.route('/process-image', methods=['POST'])
def process_image():
    file = request.files['image']
    image = Image.open(file.stream).convert('RGB')
    original = np.array(image)
    original_rgb = cv2.cvtColor(original, cv2.COLOR_RGB2BGR)

    model_yolo = YOLO("yolov8n.pt")
    results = model_yolo(original_rgb)
    boxes = results[0].boxes

    for box in boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        roi = original_rgb[y1:y2, x1:x2]
        content_tensor = image_loader_from_array(roi)
        input_tensor = content_tensor.clone()

        t_model, s_losses, c_losses = get_style_model_and_losses(
            cnn, cnn_normalization_mean, cnn_normalization_std, style_imgs, content_tensor
        )
        output = run_style_transfer(t_model, input_tensor, s_losses, c_losses)

        output_np = output.squeeze(0).cpu().detach().numpy().transpose(1,2,0)
        output_np = (output_np * 255).astype(np.uint8)
        output_np_resized = cv2.resize(output_np, (x2 - x1, y2 - y1))
        original_rgb[y1:y2, x1:x2] = output_np_resized

    result_bgr = cv2.cvtColor(original_rgb, cv2.COLOR_RGB2BGR)
    _, img_encoded = cv2.imencode('.jpg', result_bgr)
    return send_file(io.BytesIO(img_encoded.tobytes()), mimetype='image/jpeg')

# Iniciar ngrok y Flask
from pyngrok import ngrok, conf
#conf.get_default().auth_token = "2xi4CaOgnyCNHCbUulyARbFjLjm_31UWdgoTuDNST2pwaxVEQ"
#public_url = ngrok.connect(5000)
#print("\nðŸš€ Tu API pÃºblica:", public_url)
#app.run()
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))